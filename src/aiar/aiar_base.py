"""
aiar: AI Archive - Self-extracting script generated by aiar-py.

This will generate a self-extracting script. The generated script will contain 
the files from a given directory and its subdirectories and will use the .gitignore
rules to determine which files to include.

The archive format is intended to be simple for an LLM to generate or consume and the 
generated script's embedded text files will be contained without needing any escaping 
or special handling, they are literally copied to the output file except for text files
that don't have a trailing newline in while a newline will be added to the end of the file.


"""
import argparse
from functools import lru_cache
import os
import sys
from typing import Generator
import uuid
from pathlib import Path

# The 'pathspec' library is the standard for parsing .gitignore files.
# This script will check if it's installed and provide instructions if not.
try:
    import pathspec
except ImportError:
    print(
        "Warning: 'pathspec' library not found. .gitignore parsing will be skipped.",
        file=sys.stderr,
    )
    print("         Install it with: pip install pathspec", file=sys.stderr)
    pathspec = None

# This is the static bash script that will unpack the archive.
# The unique separator is injected into it when the script is generated.
AIAR_HEADER = """#!/bin/bash
# aiar: AI Archive - Self-extracting script generated by aiar-py.

# Note to LLMS, this archive is contains multiple files with separator lines.
# Text files are contained between separators verbatim, binary files are base64-encoded.

SEPARATOR="{separator}"
writing=false

# Function to report errors and exit cleanly
handle_error() {{
  echo "Error: $1" >&2
  exit 1
}}

# Function to close the previous file descriptor and wait for bg processes
close_previous_fd() {{
    if [ "$writing" = true ]; then
        exec 3>&-
        # Wait for any background process (like base64) to finish
        wait 2>/dev/null || true
    fi
    writing=false
}}

while read -r line; do
  if [[ "$line" == "$SEPARATOR" * ]]; then
    close_previous_fd

    payload="${{line#$SEPARATOR}}"
    IFS=':' read -r type filepath <<< "$payload"

    if [ -n "$filepath" -a ! -e "$filepath" ]; then
      echo "Creating: $filepath"
      mkdir -p "$(dirname "$filepath")" || handle_error "Cannot create directory for '$filepath'."

      if [ "$type" == "b" ]; then
        # Use process substitution to pipe output to base64 decoder
        exec 3> >(base64 -d > "$filepath") || handle_error "Cannot start base64 process for '$filepath'."
        writing=true
      elif [ "$type" == "t" ]; then
        exec 3>"$filepath" || handle_error "Cannot open '$filepath' for writing."
        writing=true
      else
        handle_error "Invalid file type '$type' in separator."
      fi
    else
        echo "Skipping already existing file: '$payload'"
    fi
  elif [ "$writing" = true ]; then
    echo "$line" >&3
  fi
done < "$0"

close_previous_fd # Close the very last file

echo "Extraction complete."
exit 0

# --- DATA ---
"""

# This is the static python script that will unpack the archive.
# The unique separator is injected into it when the script is generated.
# The content will need to have "# " prepended to each line.
AIAR_PYTHON_HEADER = r"""
import sys, os, re, base64
from pathlib import Path

SEP = re.escape("{separator}")

def _safe_dest(rel: str) -> Path:
    p = Path(rel)
    if p.is_absolute():
        raise ValueError(f"Absolute path not allowed: {{rel}}")
    dest = (Path(".") / p).resolve()
    if Path(".").resolve() not in (set(dest.parents) | {{dest}}):
        raise ValueError(f"Path escapes output root: {{rel}}")
    return dest

def extract_all():
    with open(__file__, "r", encoding="utf-8") as f:
        script_content = f.read()

    pat = re.compile(
        rf"^# ?{{SEP}}([tb]):([^\n]+)\n(.*?)(?=^# ?{{SEP}}[tb]:|\Z)",
        re.DOTALL | re.MULTILINE,)

    any_found = False
    for ftype, path, body in pat.findall(script_content):
        any_found = True
        path = path.strip()
        try:
            dest = _safe_dest(path)
        except ValueError as e:
            print(f"Warning: {{e}}. Skipping.")
            continue

        if dest.exists():
            print(f"Skipping already existing file: '{{dest}}'")
            continue

        print(f"Creating: {{dest}}")
        dest.parent.mkdir(parents=True, exist_ok=True)
        
        # The captured body is still commented. We must uncomment it.
        # This regex removes a leading '#' and an optional space from each line.
        uncommented_body = re.sub(r"^# ?", "", body, flags=re.MULTILINE)
        
        if ftype == "t":
            with open(dest, "w", encoding="utf-8", newline="\n") as out:
                out.write(uncommented_body)
        else:  # binary
            with open(dest, "wb") as out:
                out.write(base64.b64decode(uncommented_body.strip().encode("ascii"), validate=False))

    if not any_found:
        print("Error: No payload sections found in data block.")
        sys.exit(1)

extract_all()
print("Extraction complete.")
sys.exit(0)
"""

def find_git_root(start_path):
    """Find the root of the git repository."""
    p = Path(start_path).resolve()
    while p != p.parent:
        if (p / ".git").exists():
            return p
        p = p.parent
    return None


@lru_cache(maxsize=128)
def get_gitignore_spec(start_path, use_gitignore) -> pathspec.PathSpec | None:
    """Loads .gitignore rules from the repository root."""
    if not use_gitignore or not pathspec:
        return None

    git_root = find_git_root(start_path)
    if not git_root:
        return None

    gitignore_path = git_root / ".gitignore"
    if gitignore_path.is_file():
        with open(gitignore_path, "r") as f:
            return pathspec.PathSpec.from_lines("gitwildmatch", f)
    return None


def find_files_to_archive(paths, spec, base_dir) -> Generator[Path, None, None]:
    """Walks through input paths and yields files that are not ignored.

    - Always passes POSIX-style relative paths to the ignore matcher
    - Prunes ignored directories (e.g., "node_modules/") during traversal
    """
    for path_arg in paths:
        path_obj = Path(path_arg).resolve()
        if path_obj.is_file():
            rel = path_obj.relative_to(base_dir).as_posix()
            if spec and spec.match_file(rel):
                continue
            yield path_obj
            continue

        for root, dirnames, files in os.walk(path_obj):
            root_path = Path(root)

            # Prune ignored directories so we don't descend into them
            if spec and dirnames:
                kept = []
                for d in dirnames:
                    rel_dir = (root_path / d).relative_to(base_dir).as_posix()
                    # Check both with and without trailing slash for directory patterns
                    # .gitignore patterns like "__pycache__/" and "node_modules/" should match
                    if spec.match_file(rel_dir) or spec.match_file(rel_dir + "/"):
                        continue
                    kept.append(d)
                # Modify dirnames in-place for os.walk to respect pruning
                dirnames[:] = kept

            for filename in files:
                full_path = root_path / filename
                rel_file = full_path.relative_to(base_dir).as_posix()

                if spec and spec.match_file(rel_file):
                    continue

                yield full_path


def is_binary_file(filepath):
    """Detect if a file is binary by checking for null bytes in the first chunk."""
    try:
        with open(filepath, "rb") as f:
            chunk = f.read(8192)
            return b"\x00" in chunk
    except Exception:
        return False


def _write_aiar_data_section(output_file, files_to_archive, base_dir, separator, binary_all=False):
    """Common function to write the data section of aiar archives.
    
    This handles the actual file encoding and writing, used by both bash and bare formats.
    
    Args:
        output_file: File object to write the archive to
        files_to_archive: Set/list of Path objects to include
        base_dir: Base directory for relative paths
        separator: The separator string to use
        binary_all: If True, encode all files as binary (base64)
    """
    import base64
    
    sorted_files = sorted(list(files_to_archive))

    for filepath in sorted_files:
        try:
            # Create a relative path for the archive to preserve structure.
            relative_path = filepath.relative_to(base_dir).as_posix()

            # Determine if file should be binary
            is_binary = binary_all or is_binary_file(filepath)
            
            if is_binary:
                # Binary file: SEPARATOR:b:filepath
                output_file.write(f"{separator}b:{relative_path}\n")
                with open(filepath, "rb") as f:
                    data = f.read()
                    encoded = base64.b64encode(data).decode("ascii")
                    # Write base64 in chunks of 76 chars for readability
                    for i in range(0, len(encoded), 76):
                        output_file.write(encoded[i:i+76] + "\n")
            else:
                # Text file: SEPARATOR:t:filepath
                output_file.write(f"{separator}t:{relative_path}\n")
                with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
                    # Read entire content to preserve files without trailing newline
                    content = f.read()
                    output_file.write(content)
                    # Ensure we end with a newline for proper parsing
                    if content and not content.endswith("\n"):
                        output_file.write("\n")
                    
        except Exception as e:
            print(
                f"Warning: Could not read file '{filepath}'. Skipping. Error: {e}",
                file=sys.stderr,
            )


def create_aiar_bash(output_file, files_to_archive, base_dir, binary_all=False):
    """Generates a bash self-extracting aiar script.
    
    Binary files are base64-encoded with :b: marker.
    Text files use :t: marker and are written line-by-line.
    Format: SEPARATOR:X:Y:filepath where X is UUID and Y is 'b' or 't'
    
    Note, a limitation of text files is that files without a trailing newline 
    will have a newline added to the end of the file. If this is undesirable,
    you can use the --binary-all option to encode all files as binary.
    
    Args:
        output_file: File object to write the archive to
        files_to_archive: Set/list of Path objects to include
        base_dir: Base directory for relative paths
        binary_all: If True, encode all files as binary (base64)
    """
    # Generate a unique separator to prevent collisions with file content.
    # Format: ++++++++++--------:UUID:
    separator_uuid = str(uuid.uuid4())
    separator = f"++++++++++--------:{separator_uuid}:"

    # Write the header, injecting the unique separator.
    output_file.write(AIAR_HEADER.format(separator=separator))

    # Write the data section using the common function
    _write_aiar_data_section(output_file, files_to_archive, base_dir, separator, binary_all)


def create_aiar_python(output_file, files_to_archive, base_dir, binary_all=False):
    """Generates a Python self-extracting aiar script.
    
    Binary files are base64-encoded with :b: marker.
    Text files use :t: marker and are embedded as commented text.
    Format: # SEPARATOR:X:Y:filepath where X is UUID and Y is 'b' or 't'
    
    The Python script uses regex to extract files from the commented sections.
    
    Args:
        output_file: File object to write the archive to
        files_to_archive: Set/list of Path objects to include
        base_dir: Base directory for relative paths
        binary_all: If True, encode all files as binary (base64)
    """
    import base64
    
    # Generate a unique separator to prevent collisions with file content.
    # Format: ++++++++++--------:UUID:
    separator_uuid = str(uuid.uuid4())
    separator = f"++++++++++--------:{separator_uuid}:"

    # Write the header, injecting the unique separator.
    output_file.write(AIAR_PYTHON_HEADER.format(separator=separator))

    sorted_files = sorted(list(files_to_archive))

    for filepath in sorted_files:
        try:
            # Create a relative path for the archive to preserve structure.
            relative_path = filepath.relative_to(base_dir).as_posix()

            # Determine if file should be binary
            is_binary = binary_all or is_binary_file(filepath)
            
            if is_binary:
                # Binary file: # SEPARATOR:b:filepath
                output_file.write(f"# {separator}b:{relative_path}\n")
                with open(filepath, "rb") as f:
                    data = f.read()
                    encoded = base64.b64encode(data).decode("ascii")
                    # Write base64 in chunks of 76 chars for readability, commented
                    for i in range(0, len(encoded), 76):
                        output_file.write(f"# {encoded[i:i+76]}\n")
            else:
                # Text file: # SEPARATOR:t:filepath
                output_file.write(f"# {separator}t:{relative_path}\n")
                with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
                    # Read entire content to preserve files without trailing newline
                    content = f.read()
                    # Comment each line of the content
                    for line in content.splitlines(keepends=True):
                        output_file.write(f"# {line}")
                    # Ensure we end with a newline for proper parsing
                    if content and not content.endswith("\n"):
                        output_file.write("\n")
                    
        except Exception as e:
            print(
                f"Warning: Could not read file '{filepath}'. Skipping. Error: {e}",
                file=sys.stderr,
            )


def create_aiar_bare(output_file, files_to_archive, base_dir, binary_all=False):
    """Generates a bare data file without self-extraction script.
    
    This format only includes the separator definition and the file data,
    without any extraction logic. Useful for embedding in other tools or
    for manual processing.
    
    Binary files are base64-encoded with :b: marker.
    Text files use :t: marker.
    Format: SEPARATOR:X:Y:filepath where X is UUID and Y is 'b' or 't'
    
    Args:
        output_file: File object to write the archive to
        files_to_archive: Set/list of Path objects to include
        base_dir: Base directory for relative paths
        binary_all: If True, encode all files as binary (base64)
    """
    # Generate a unique separator to prevent collisions with file content.
    # Format: ++++++++++--------:UUID:
    separator_uuid = str(uuid.uuid4())
    separator = f"++++++++++--------:{separator_uuid}:"

    # Write just the separator definition
    output_file.write(f"SEPARATOR=\"{separator}\"\n\n")

    # Write the data section using the common function
    _write_aiar_data_section(output_file, files_to_archive, base_dir, separator, binary_all)


def create_aiar(output_file, files_to_archive, base_dir, binary_all=False, lang="bash"):
    """Dispatches to the appropriate aiar generator based on language.
    
    Args:
        output_file: File object to write the archive to
        files_to_archive: Set/list of Path objects to include
        base_dir: Base directory for relative paths
        binary_all: If True, encode all files as binary (base64)
        lang: Language for self-extractor ("bash", "py", or "bare")
    """
    if lang == "py":
        create_aiar_python(output_file, files_to_archive, base_dir, binary_all)
    elif lang == "bare":
        create_aiar_bare(output_file, files_to_archive, base_dir, binary_all)
    else:
        create_aiar_bash(output_file, files_to_archive, base_dir, binary_all)


def _main():
    parser = argparse.ArgumentParser(
        description="Generate an aiar (AI Archive) self-extracting shell script.",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument(
        "paths", nargs="+", help="One or more files or directories to archive."
    )
    parser.add_argument(
        "-o",
        "--output",
        help="Output file for the aiar script. Defaults to stdout.",
    )
    parser.add_argument(
        "--no-gitignore",
        action="store_true",
        help="Disable using .gitignore files for exclusion.",
    )
    parser.add_argument(
        "--binary-all",
        action="store_true",
        help="Treat all files as binary (base64-encode everything).",
    )
    parser.add_argument(
        "--lang",
        choices=["bash", "py", "bare"],
        default="bash",
        help="Language for self-extracting script: bash, py, or bare (data only, default: bash).",
    )

    args = parser.parse_args()
    
    resolved_paths = [Path(p).resolve() for p in args.paths]
    base_dir = Path(os.path.commonpath(resolved_paths))
    if base_dir.is_file():
        base_dir = base_dir.parent

    spec = get_gitignore_spec(base_dir, not args.no_gitignore)
    files_to_process = find_files_to_archive(resolved_paths, spec, base_dir)

    # Use a set to handle potential duplicates if paths overlap
    unique_files = set(files_to_process)

    if not unique_files:
        print("No files found to archive.", file=sys.stderr)
        return

    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            create_aiar(f, unique_files, base_dir, binary_all=args.binary_all, lang=args.lang)
        print(f"aiar script created at '{args.output}'")
        os.chmod(args.output, 0o755) # Make it executable
    else:
        create_aiar(sys.stdout, unique_files, base_dir, binary_all=args.binary_all, lang=args.lang)


if __name__ == "__main__":
    import sys
    sys.argv = [
        sys.argv[0],
        "grip-react",
        "-o",
        "grip-react.aiar",
    ]
    _main()
